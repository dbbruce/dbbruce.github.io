<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>012-scrapy基础 | 董勉 | 技术博客 | 成功的秘诀在于耐心和求胜心.</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
    <meta name="description" content="桑弧蓬矢">
  
  
  
    <link rel="alternate" href="/atom.xml" title="董勉 | 技术博客 | 成功的秘诀在于耐心和求胜心." type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="/localshare/css/share.css">

  
  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">董勉 | 技术博客 | 成功的秘诀在于耐心和求胜心.</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">此生当克己勤免，自强不息 .</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/."><i class="fa fa-home"></i> 首页</a>
        
          <a class="main-nav-link" href="/archives/"><i class="fa fa-archive"></i> 归档</a>
        
          <a class="main-nav-link" href="/about/"><i class="fa fa-user"></i> 关于</a>
        
      </nav>
    </div>
    <div id="search-form">
      <div id="result-mask" class="hide"></div>
      <label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label>
      <div id="result-wrap" class="hide">
        <div id="search-result"></div>
      </div>
      <div class="hide">
        <template id="search-tpl">
          <div class="item">
            <a href="/{path}" title="{title}">
              <div class="title">{title}</div>
              <div class="time">{date}</div>
              <div class="tags">{tags}</div>
            </a>
          </div>
        </template>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-爬虫/基础/012-scrapy基础" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      012-scrapy基础
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2023-08-19T07:04:52.000Z" itemprop="datePublished">2023年08月19日</time>
</span>
      
  <div class="article-category">
    <i class="fa fa-classify"></i>
    <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB%E7%B1%BB/">爬虫类</a> > <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB%E7%B1%BB/%E5%9F%BA%E7%A1%80/">基础</a>
  </div>

      
        <span class="article-views">
  <i class="fa fa-views"></i>
  <i id="busuanzi_container_page_pv">
      <i id="busuanzi_value_page_pv"></i>
  </i>
</span>

      
      
<a href="/2023/08/19/%E7%88%AC%E8%99%AB/%E5%9F%BA%E7%A1%80/012-scrapy%E5%9F%BA%E7%A1%80/#comments" class="article-comment-link">
  
    
    
    
    
    
  
<!--   <i class="fa fa-commt"></i> -->
<!--   留言 -->
</a>


    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="最新版"><a href="#最新版" class="headerlink" title="最新版"></a>最新版</h4><blockquote>
<p>pip install scrapy</p>
</blockquote>
<h4 id="框架结构"><a href="#框架结构" class="headerlink" title="框架结构"></a>框架结构</h4><p>Scrapy Engin(引擎):Scrapy框架的核心部分负责在Spider和ltem Pipeline、Downloader、Scheduler中间通信、传递数据等。<br>Spider(爬虫):发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。<br>Scheduler(调度器):负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等<br>Downloader(下载器):负责接收引擎过来的下载请求，然后去网络上下载对应的数据再交给引擎<br>Item Pipeline(管道):负责将爬虫传递过来的数据进行保存。<br>Downloader Middlewares(下载中间件):可以扩展下载器和引擎之间通信功能的中间件<br>Spider Middlewares(Spider中间件):可以扩展引擎和爬虫之间通信功能的中间件</p>
<span id="more"></span>
<p><img src="/../../../images/%E7%88%AC%E8%99%AB/%E5%9F%BA%E7%A1%80/WX20240530-141424.png" alt="WX20240530-141424.png"></p>
<h4 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h4><blockquote>
<p>scrapy startproject douban(项目名)</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(spider-env) dbbruce@dbburce test1 % tree douban </span><br><span class="line">douban</span><br><span class="line">├── douban</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py          # 定义数据</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py      # 处理数据</span><br><span class="line">│   ├── settings.py       # 各种设置 </span><br><span class="line">│   └── spiders           # 爬虫目录</span><br><span class="line">│       └── __init__.py</span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>1、创建一个爬虫文件（进入项目）</li>
</ul>
<blockquote>
<p>cd douban<br>scrapy genspider 爬虫名 域名(限定域名，只抓取这个域名)</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">douban</span><br><span class="line">├── douban</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── xiao.py</span><br><span class="line">└── scrapy.cfg</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">XiaoSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;xiao&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;douban.com&quot;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;https://douban.com&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行爬虫</span></span><br><span class="line">scrapy crawl xiao</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /douban/douban/spiders/top250book.py</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoubanSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;xiao&#x27;</span>  <span class="comment"># 爬虫名称</span></span><br><span class="line">    allowed_domains =[<span class="string">&#x27;book.douban.com/top250&#x27;</span>]  <span class="comment"># 定义运行爬取的域名</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://book.douban.com/top250&#x27;</span>]    <span class="comment"># 定义起始的网址</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):   <span class="comment"># 解析函数</span></span><br><span class="line">        <span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>2、修改请求头</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /douban/douban/settings.py</span></span><br><span class="line"></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27; text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27; zh-CN,zh;q=0.9,en;q=0.8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27; book.douban.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27; Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>3、遵守robots协议</p>
<blockquote>
<p>True遵守协议，False不遵守，一般都是不遵守</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /douban/douban/settings.py</span></span><br><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>4、创建一个启动脚本</p>
<blockquote>
<p>scrapy crawl 爬虫名<br><img src="/../../../images/%E7%88%AC%E8%99%AB/%E5%9F%BA%E7%A1%80/img_7.png" alt="img_7.png"></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># start.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line">cmdline.execute([ <span class="string">&quot;scrapy&quot;</span>,  <span class="string">&quot;crawl&quot;</span>,  <span class="string">&quot;douban&quot;</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>5、使用pipeline后需要修改配置文件，管道要好使，必须启用这里</p>
<blockquote>
<p>300是优先级，数越大优先级越低</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /douban/douban/settings.py</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># key管道的路径，value 管道优先级，数越小，优先级越高</span></span><br><span class="line">   <span class="string">&quot;douban.pipelines.DoubanPipeline&quot;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="douban的一个实例"><a href="#douban的一个实例" class="headerlink" title="douban的一个实例"></a>douban的一个实例</h4><p>项目结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">douban</span><br><span class="line">├── book.xlsx</span><br><span class="line">├── douban</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── top250book.py</span><br><span class="line">├── scrapy.cfg</span><br><span class="line">└── start.py</span><br></pre></td></tr></table></figure>
<p>爬虫 : top250book.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> DoubanItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoubanSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;douban&#x27;</span>  <span class="comment"># 爬虫名称</span></span><br><span class="line">    allowed_domains =[<span class="string">&#x27;book.douban.com/top250&#x27;</span>]  <span class="comment"># 定义运行爬取的域名</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://book.douban.com/top250&#x27;</span>]    <span class="comment"># 定义起始的网址</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        bs = BeautifulSoup(response.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">        tr_tag = bs.find_all(<span class="string">&#x27;tr&#x27;</span>, class_=<span class="string">&#x27;item&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> tr <span class="keyword">in</span> tr_tag:</span><br><span class="line">            item = DoubanItem()</span><br><span class="line">            title = tr.find_all(<span class="string">&#x27;a&#x27;</span>)[<span class="number">1</span>][<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">            publish = tr.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;pl&#x27;</span>).text</span><br><span class="line">            score = tr.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&#x27;rating_nums&#x27;</span>).text</span><br><span class="line">            item[<span class="string">&#x27;title&#x27;</span>] = title</span><br><span class="line">            item[<span class="string">&#x27;publish&#x27;</span>] = publish</span><br><span class="line">            item[<span class="string">&#x27;score&#x27;</span>] = score</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> item </span><br></pre></td></tr></table></figure>
<p>存储对象：items.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Doubanitem</span>(scrapy.Item):</span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    publish = scrapy.Field()</span><br><span class="line">    score = scrapy.Field()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>执行存储：pipelines.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openpyxl</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoubanPipeline</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.wb = openpyxl.Workbook()</span><br><span class="line">        self.ws = self.wb.active</span><br><span class="line">        self.ws.append([<span class="string">&#x27;名称&#x27;</span>,<span class="string">&#x27;出版信息&#x27;</span>,<span class="string">&#x27;评分&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        line = [item[<span class="string">&#x27;title&#x27;</span>],item[<span class="string">&#x27;publish&#x27;</span>],item[<span class="string">&#x27;score&#x27;</span>]]</span><br><span class="line">        self.ws.append(line)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):  <span class="comment">#注意spider这个参数，要写</span></span><br><span class="line">        self.wb.save(<span class="string">&#x27;book.xlsx&#x27;</span>)</span><br><span class="line">        self.wb.close()</span><br></pre></td></tr></table></figure>
<p>配置文件 ： settings.py &#x3D; 请求头 、pipeline、robots协议</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27; text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27; zh-CN,zh;q=0.9,en;q=0.8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27; book.douban.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27; Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&quot;douban.pipelines.DoubanPipeline&quot;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="yield-推送数据"><a href="#yield-推送数据" class="headerlink" title="yield 推送数据"></a>yield 推送数据</h4><blockquote>
<p>yield 的三种数据</p>
</blockquote>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yield&#123;&#125; 字典推送给pipeline</span><br><span class="line">yield item 对象 推送给pipeline</span><br><span class="line">yield scrap.Request()Request对象 ,谁送给调度器</span><br></pre></td></tr></table></figure>
<h4 id="创建项目和爬虫"><a href="#创建项目和爬虫" class="headerlink" title="创建项目和爬虫"></a>创建项目和爬虫</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">scrapy startproject story</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cd</span> story</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">scrapy genspider qustory qu.la  <span class="comment"># 爬虫文件名 域名</span></span></span><br></pre></td></tr></table></figure>
<h4 id="scrapy提取数据的方法"><a href="#scrapy提取数据的方法" class="headerlink" title="scrapy提取数据的方法"></a>scrapy提取数据的方法</h4><p>注意：scrapy xpath获取的是一个selector对象，使用extract或者extract first获取数据</p>
<table>
<thead>
<tr>
<th>方法&#x2F;函数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>xpath()</td>
<td>它返回选择器列表，它代表由指定的Xpath表达式参数选择的节点</td>
</tr>
<tr>
<td>css()</td>
<td>它返回选择器列表，代表由指定CSS表达式作为参数所选择的节点</td>
</tr>
<tr>
<td>re()</td>
<td>它返回Unicode字符串列表，当正则表达式被赋予作为参数时提取</td>
</tr>
<tr>
<td>extract()</td>
<td>它返回一个Unicode字符串以及所选择数据 ，返回列表</td>
</tr>
<tr>
<td>extract first()</td>
<td>它返回第一个Unicode字符串以及所选数据 ，返回字符串</td>
</tr>
</tbody></table>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul>
<li>使用string()，可以只取元素对象中的文字</li>
<li>extract 返回列表，extract_first 返回字符串</li>
<li>yield 直接返回一个字典，直接将数据推送个pipeline，可以直接在pipeline文件中操作<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># qustory.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QustorySpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;qustory&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;qu.la&quot;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;https://qu.la&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        title = response.xpath(<span class="string">&#x27;//h1[@class=&quot;title&quot;]/text()&#x27;</span>).extract()</span><br><span class="line">        content = response.xpath(<span class="string">&#x27;string(//div[@id=&quot;content&quot;])&#x27;</span>).extract_first()</span><br><span class="line">        next_url = response.xpath(<span class="string">&#x27;//div[@class=&quot;section-opt&quot;]/a[3]/@href&#x27;</span>).extract_first()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 返回数据给pipline，其实先给引擎，再给pipline</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span>: title,</span><br><span class="line">            <span class="string">&#x27;content&#x27;</span>: content,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(next_url, callback=self.parse())</span><br></pre></td></tr></table></figure>
直接在pipeline中操作数据<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pipelines.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StoryPipeline</span>: <span class="comment"># 这个类随意定义</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>): <span class="comment"># 这个方法定死的， item是数据</span></span><br><span class="line">        info = <span class="string">&#x27;&#x27;</span>.join([item[<span class="string">&#x27;title&#x27;</span>], item[<span class="string">&#x27;content&#x27;</span>], <span class="string">&#x27;\n&#x27;</span>])</span><br><span class="line">        self.file.write(info)</span><br><span class="line">        <span class="keyword">return</span> item   <span class="comment"># 给下一个管道</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.file = <span class="built_in">open</span>(<span class="string">&#x27;story.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自己新加一个Pipeline，需要加settings</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NewTestPipeline</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>): <span class="comment"># 这个方法定死的， item是数据</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;test&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> item  <span class="comment"># 必须return东西，否则下一个管道收不到数据了</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&quot;douban.pipelines.DoubanPipeline&quot;</span>: <span class="number">300</span>,</span><br><span class="line">   <span class="string">&quot;douban.pipelines.NewTestPipeline&quot;</span>: <span class="number">200</span>, <span class="comment"># 先执行这个</span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="settings-配置文件"><a href="#settings-配置文件" class="headerlink" title="settings 配置文件"></a>settings 配置文件</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME=&#x27;story&#x27;爬虫的名字，在使用startproject命令创建时自动被赋值</span><br><span class="line">CONCURRENT_REQUESTS =32 并发请求的最大值，默认为16</span><br><span class="line">DEFAULT_REOUEST_HEADERS 默认的请求头</span><br><span class="line">DOWNLOAD_DELAY =3 下载延迟、秒</span><br><span class="line">LOG_ENABLED=False 默认为True,显示日志信息，需要自己写</span><br></pre></td></tr></table></figure>
<h4 id="不显示运行时看到很多调试信息"><a href="#不显示运行时看到很多调试信息" class="headerlink" title="不显示运行时看到很多调试信息"></a>不显示运行时看到很多调试信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim settings.py</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">日志级别：DEBUG，INFO, WARNING, ERROR , CRITICAL</span></span><br><span class="line">LOG_LEVEL = &quot;WARNING&quot;</span><br></pre></td></tr></table></figure>
<h4 id="selector提取内容"><a href="#selector提取内容" class="headerlink" title="selector提取内容"></a>selector提取内容</h4><p>extract(),没有内容会报错</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.xpath(<span class="string">&quot;//ul.text()&quot;</span>).extract()</span><br></pre></td></tr></table></figure>
<p>extract_first(),没有内容返回None,这个比较好</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.xpath(<span class="string">&quot;//ul.text()&quot;</span>).extract_first()</span><br></pre></td></tr></table></figure>

        
            <div id="toc-article">
                
  <div class="widget-wrap" id="toc-wrap">
    <h3 class="widget-title"><i class="fa fa-toc"></i> 文章目录</h3>
    <div class="widget">
      <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E6%96%B0%E7%89%88"><span class="toc-text">最新版</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%86%E6%9E%B6%E7%BB%93%E6%9E%84"><span class="toc-text">框架结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-text">创建项目</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#douban%E7%9A%84%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B"><span class="toc-text">douban的一个实例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#yield-%E6%8E%A8%E9%80%81%E6%95%B0%E6%8D%AE"><span class="toc-text">yield 推送数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%E5%92%8C%E7%88%AC%E8%99%AB"><span class="toc-text">创建项目和爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#scrapy%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-text">scrapy提取数据的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-text"></span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#settings-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">settings 配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8D%E6%98%BE%E7%A4%BA%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9C%8B%E5%88%B0%E5%BE%88%E5%A4%9A%E8%B0%83%E8%AF%95%E4%BF%A1%E6%81%AF"><span class="toc-text">不显示运行时看到很多调试信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#selector%E6%8F%90%E5%8F%96%E5%86%85%E5%AE%B9"><span class="toc-text">selector提取内容</span></a></li></ol>
    </div>
  </div>


            </div>
        
<!--          -->
<!--           <blockquote id="copyright"> -->
<!--               <p>原文链接: <a href="https://dbbruce.github.io/2023/08/19/爬虫/基础/012-scrapy基础/">https://dbbruce.github.io/2023/08/19/爬虫/基础/012-scrapy基础/</a></p> -->
<!--               <p>版权声明: 转载请注明出处.</p> -->
<!--           </blockquote> -->
<!--          -->
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
          <!--  -->
<!--     <div class="social-share"> -->
<!--       <span>分享到:</span> -->
<!--     </div> -->
<!--  -->
<!--  -->

        </div>
      
      
        
<nav id="article-nav">
  
    <a href="/2023/08/19/%E7%88%AC%E8%99%AB/%E5%9F%BA%E7%A1%80/013-CrawlSpider%E5%9F%BA%E7%A1%80/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          013-CrawlSpider基础
        
      </div>
    </a>
  
  
    <a href="/2023/08/19/odoo/odoo%E7%9F%A5%E8%AF%86%E7%82%B95-PostgreSQL/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">
        
          odoo知识点(五)-PostgreSQL
        
      </div>
    </a>
  
</nav>

      
      
        








      
    </footer>
  </div>
</article>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-posts"></i> 最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2035/08/08/%E9%A1%B9%E7%9B%AE/HCM%E6%95%99%E7%A8%8B/999-%E5%AE%9E%E4%BE%8B:%E9%97%AE%E9%A2%98%E5%90%88%E9%9B%86/">999-实例:问题合集</a>
          </li>
        
          <li>
            <a href="/2025/12/25/python/%E5%9F%BA%E7%A1%80/python%E7%89%B9%E6%AE%8A%E5%B1%9E%E6%80%A7%E5%92%8C%E6%96%B9%E6%B3%95/">python特殊属性和方法</a>
          </li>
        
          <li>
            <a href="/2025/08/14/%E9%A1%B9%E7%9B%AE/HCM%E6%95%99%E7%A8%8B/116-%E5%AE%9E%E4%BE%8B:%E6%B0%91%E4%B8%BB%E6%B5%8B%E8%AF%84-%E4%B8%8B%E8%BD%BD%E4%BA%8C%E7%BB%B4%E7%A0%81/">116-实例:民主测评-下载二维码</a>
          </li>
        
          <li>
            <a href="/2025/08/13/%E9%A1%B9%E7%9B%AE/HCM%E6%95%99%E7%A8%8B/115-%E5%AE%9E%E4%BE%8B:%E8%A1%A8%E5%8D%95-%E9%93%BE%E6%8E%A5%E5%AD%97%E6%AE%B5/">115-实例:表单-链接字段</a>
          </li>
        
          <li>
            <a href="/2025/08/13/%E9%A1%B9%E7%9B%AE/HCM%E6%95%99%E7%A8%8B/114-%E5%AE%9E%E4%BE%8B:%E4%BA%91%E5%87%BD%E6%95%B0-%E8%BF%87%E6%BB%A4%E6%9D%A1%E4%BB%B6/">114-实例:云函数-过滤条件</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-classify"></i> 分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/GO%E8%AF%AD%E8%A8%80/">GO语言</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GO%E8%AF%AD%E8%A8%80/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%9F%BA%E7%A1%80/">Python基础</a><span class="category-list-count">22</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%9F%BA%E7%A1%80/Django/">Django</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%9F%BA%E7%A1%80/%E5%8C%85%E6%96%B9%E6%B3%95/">包方法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%9F%BA%E7%A1%80/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/">异步编程</a><span class="category-list-count">12</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/git/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/odoo/">odoo</a><span class="category-list-count">11</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/odoo/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">11</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%AF%8F%E6%9C%88%E6%A6%82%E8%A6%81/">每月概要</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%AF%8F%E6%9C%88%E6%A6%82%E8%A6%81/2023/">2023</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%AF%8F%E6%9C%88%E6%A6%82%E8%A6%81/2025/">2025</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB%E7%B1%BB/">爬虫类</a><span class="category-list-count">28</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB%E7%B1%BB/%E5%8F%8D%E7%88%AC/">反爬</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB%E7%B1%BB/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">23</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB%E7%B1%BB/%E7%BC%96%E7%A0%81/">编码</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%BB%9C/">网络</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%BB%9C/%E5%BC%82%E5%B8%B8/">异常</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/">运维</a><span class="category-list-count">197</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/Git/">Git</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/Java%E7%94%9F%E6%80%81/">Java生态</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/K8S/">K8S</a><span class="category-list-count">48</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/K8S/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">45</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/K8S/%E9%94%99%E8%AF%AF/">错误</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/K8S/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%80%BB/">项目汇总</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/docker/">docker</a><span class="category-list-count">22</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/docker/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">20</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/docker/%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6/">错误集锦</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/grafana/">grafana</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/linux%E4%BA%91%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/">linux云计算基础教程</a><span class="category-list-count">63</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/memcached/">memcached</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/nginx/">nginx</a><span class="category-list-count">23</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/zabbix/">zabbix</a><span class="category-list-count">19</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/zabbix/5-0LTS/">5.0LTS</a><span class="category-list-count">19</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/">常用工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7/">抓包工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/%E8%BF%90%E7%BB%B4%E4%B8%80%E4%BA%9B%E6%8A%80%E5%B7%A7%E5%92%8C%E5%B8%B8%E8%AF%86/">运维一些技巧和常识</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E7%BB%B4/%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/">问题处理</a><span class="category-list-count">5</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9D%A2%E8%AF%95/">面试</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9D%A2%E8%AF%95/%E9%A2%98/">题</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE/">项目</a><span class="category-list-count">143</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE/HCM%E6%95%99%E7%A8%8B/">HCM教程</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE/%E5%8C%BB%E8%8D%AF%E5%85%AC%E5%8F%B8ERP/">医药公司ERP</a><span class="category-list-count">25</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE/%E5%8C%BB%E8%8D%AF%E5%85%AC%E5%8F%B8ERP/%E4%B8%9A%E5%8A%A1/">业务</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%A1%B9%E7%9B%AE/%E5%8C%BB%E8%8D%AF%E5%85%AC%E5%8F%B8ERP/%E5%9F%BA%E7%A1%80/">基础</a><span class="category-list-count">3</span></li></ul></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-archive"></i> 归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2035/">2035年</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/">2025年</a><span class="archive-list-count">122</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/">2023年</a><span class="archive-list-count">135</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022年</a><span class="archive-list-count">40</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021年</a><span class="archive-list-count">107</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020年</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018年</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/">2017年</a><span class="archive-list-count">23</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2000/">2000年</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-link"></i> 友情链接</h3>
    <div class="widget">
      <ul>
      
        <li>
          <a href="https://dbbruce.github.io/">董勉的Blog</a>
        </li>
      
      </ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <a id="totop" href="#top"></a>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
<!--       <p> -->
<!--         <a href="/sitemap.xml">网站地图</a> -->
<!--         <span> | </span><a href="/atom.xml">订阅本站</a> -->
<!--         <span> | </span><a href="/about/">联系博主</a> -->
<!--       </p> -->
<!--        -->
<!--         <p> -->
<!--           <i class="fa fa-visitors"></i> -->
<!--           <i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i> -->
<!--           ， -->
<!--           <i class="fa fa-views"></i> -->
<!--           <i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i> -->
<!--         </p> -->
<!--        -->
<!--       <p> -->
        <span>Copyright &copy; 2026 DB Bruce. 董勉的技术博客  https://dbbruce.github.io</span>
<!--         <span>Theme by <a href="https://github.com/chaooo/hexo-theme-BlueLake/" target="_blank">BlueLake.</a></span> -->
<!--         <span>Powered by <a href="https://hexo.io/" target="_blank">Hexo.</a></span> -->
<!--       </p> -->
    </div>
  </div>
</footer>

    </div>
  </div>
  
<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/search.json.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>






  
<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<!--  -->
<!--    -->
<!--     
<script src="/localshare/js/social-share.js"></script>
 -->
<!--     
<script src="/localshare/js/qrcode.js"></script>
 -->
<!--    -->
<!--    -->
<!--  -->


  

  

  

  

  

  

  

  
  





</body>
</html>